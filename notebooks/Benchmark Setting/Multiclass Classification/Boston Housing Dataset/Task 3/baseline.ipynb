{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0567ad-b2d3-4c70-99f9-cbbf8ba34f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from comparers import ModelComparer\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from util import RuleClassifier, find_counterfactuals, counterfactuals_to_constraint_matrix,\\\n",
    "                 evaluate_counterfactual_fidelity, print_complexity\n",
    "from surrogate_tree import train_surrogate_tree, tree_to_rules, plot_surrogate_tree,\\\n",
    "                 get_feature_importances, plot_feature_importances, plot_tree_leafs_for_class,\\\n",
    "                 tree_to_constraint_matrix, constraint_matrix_to_rules, extract_rules, print_rules,\\\n",
    "                 evaluate\n",
    "from tasks.boston_housing import make_task3 as make_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d016e30a-0630-4928-99e4-f564cbda6ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to unpickle estimator LabelBinarizer from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "Trying to unpickle estimator MLPClassifier from version 0.24.1 when using version 0.24.2. This might lead to breaking code or invalid results. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "clf_a, clf_b, X, y, feature_names, categorical_features, feature_precisions = make_task()\n",
    "comparer = ModelComparer(clf_a, clf_b, feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6962e63-b0cd-4418-8f91-08256b225eba",
   "metadata": {},
   "source": [
    "# Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55d5383f-12a6-4970-b6b8-4e98ea815e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mclass_diff = comparer.predict_mclass_diff(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ce2911f-0c2f-442e-b618-4285a10e0bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_per_class = {}\n",
    "for label in comparer.difference_class_names:\n",
    "    with open(f'ground_truth.{label}.pickle', 'rb') as f:\n",
    "        ground_truth_per_class[label] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc2ed4-dada-48fa-8e64-d059ce5541ab",
   "metadata": {},
   "source": [
    "Trees with depths below 7 are not complex enough to describe all instances of the difference classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "908d84f9-8d42-4ebc-a588-e117e8426038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      (0, 0)       0.86      0.86      0.86        76\n",
      "      (0, 1)       0.00      0.00      0.00        13\n",
      "      (1, 1)       0.65      0.95      0.77        58\n",
      "      (1, 2)       0.00      0.00      0.00         1\n",
      "      (2, 1)       0.00      0.00      0.00         3\n",
      "      (2, 2)       0.98      0.88      0.93        95\n",
      "\n",
      "    accuracy                           0.83       246\n",
      "   macro avg       0.41      0.45      0.43       246\n",
      "weighted avg       0.80      0.83      0.81       246\n",
      "\n",
      "CPU times: user 12.4 ms, sys: 2.92 ms, total: 15.3 ms\n",
      "Wall time: 16.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = train_surrogate_tree(X, mclass_diff, max_depth=2)\n",
    "evaluate(model, X, mclass_diff, comparer.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7520c1cc-5fd0-4dbf-9d3e-9c21a7664f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      (0, 0)       0.90      0.96      0.93        76\n",
      "      (0, 1)       0.60      0.23      0.33        13\n",
      "      (1, 1)       0.89      0.97      0.93        58\n",
      "      (1, 2)       0.00      0.00      0.00         1\n",
      "      (2, 1)       0.00      0.00      0.00         3\n",
      "      (2, 2)       0.97      0.99      0.98        95\n",
      "\n",
      "    accuracy                           0.92       246\n",
      "   macro avg       0.56      0.52      0.53       246\n",
      "weighted avg       0.89      0.92      0.90       246\n",
      "\n",
      "CPU times: user 11.3 ms, sys: 3.12 ms, total: 14.4 ms\n",
      "Wall time: 17.6 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = train_surrogate_tree(X, mclass_diff, max_depth=3)\n",
    "evaluate(model, X, mclass_diff, comparer.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3eb7793-1cb7-4c5c-b2f1-322d634b1851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      (0, 0)       0.93      0.97      0.95        76\n",
      "      (0, 1)       0.83      0.38      0.53        13\n",
      "      (1, 1)       0.90      0.98      0.94        58\n",
      "      (1, 2)       0.00      0.00      0.00         1\n",
      "      (2, 1)       0.75      1.00      0.86         3\n",
      "      (2, 2)       1.00      0.98      0.99        95\n",
      "\n",
      "    accuracy                           0.94       246\n",
      "   macro avg       0.74      0.72      0.71       246\n",
      "weighted avg       0.94      0.94      0.94       246\n",
      "\n",
      "CPU times: user 12.3 ms, sys: 3.36 ms, total: 15.7 ms\n",
      "Wall time: 16.5 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = train_surrogate_tree(X, mclass_diff, max_depth=4)\n",
    "evaluate(model, X, mclass_diff, comparer.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9de11d01-10bb-4201-9eda-7db03a6ccae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      (0, 0)       0.99      0.99      0.99        76\n",
      "      (0, 1)       0.85      0.85      0.85        13\n",
      "      (1, 1)       0.97      0.97      0.97        58\n",
      "      (1, 2)       1.00      1.00      1.00         1\n",
      "      (2, 1)       1.00      1.00      1.00         3\n",
      "      (2, 2)       1.00      1.00      1.00        95\n",
      "\n",
      "    accuracy                           0.98       246\n",
      "   macro avg       0.97      0.97      0.97       246\n",
      "weighted avg       0.98      0.98      0.98       246\n",
      "\n",
      "CPU times: user 9.07 ms, sys: 2.13 ms, total: 11.2 ms\n",
      "Wall time: 12.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = train_surrogate_tree(X, mclass_diff, max_depth=5)\n",
    "evaluate(model, X, mclass_diff, comparer.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38678792-59f8-416a-9b7d-e7fa42f88767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      (0, 0)       0.97      1.00      0.99        76\n",
      "      (0, 1)       1.00      0.92      0.96        13\n",
      "      (1, 1)       1.00      0.98      0.99        58\n",
      "      (1, 2)       1.00      1.00      1.00         1\n",
      "      (2, 1)       1.00      1.00      1.00         3\n",
      "      (2, 2)       1.00      1.00      1.00        95\n",
      "\n",
      "    accuracy                           0.99       246\n",
      "   macro avg       1.00      0.98      0.99       246\n",
      "weighted avg       0.99      0.99      0.99       246\n",
      "\n",
      "CPU times: user 10.6 ms, sys: 2.1 ms, total: 12.7 ms\n",
      "Wall time: 14.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = train_surrogate_tree(X, mclass_diff, max_depth=6)\n",
    "evaluate(model, X, mclass_diff, comparer.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ed32a-1a95-43ee-b721-40e6d9123a62",
   "metadata": {},
   "source": [
    "## Tree with Depth 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0b749f4-73ed-42e2-8fec-72b93cc4db70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      (0, 0)       0.99      1.00      0.99        76\n",
      "      (0, 1)       1.00      1.00      1.00        13\n",
      "      (1, 1)       1.00      0.98      0.99        58\n",
      "      (1, 2)       1.00      1.00      1.00         1\n",
      "      (2, 1)       1.00      1.00      1.00         3\n",
      "      (2, 2)       1.00      1.00      1.00        95\n",
      "\n",
      "    accuracy                           1.00       246\n",
      "   macro avg       1.00      1.00      1.00       246\n",
      "weighted avg       1.00      1.00      1.00       246\n",
      "\n",
      "CPU times: user 10.4 ms, sys: 2.49 ms, total: 12.9 ms\n",
      "Wall time: 14.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = train_surrogate_tree(X, mclass_diff, max_depth=7)\n",
    "evaluate(model, X, mclass_diff, comparer.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faa72422-1fe4-4b58-be9d-3f41aa9c182e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances, feature_order = get_feature_importances(model)\n",
    "plot_feature_importances(feature_names, feature_importances, feature_order, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65747d00-860f-41b3-933f-bdb23c5be46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. CRIM <= 0.9839633405208588 and NOX > 0.5909999907016754 and RM <= 6.0940001010894775 and 12.607422828674316 < LSTAT <= 17.722667694091797 => (0, 1) [0, 4, 0, 0, 0, 0]\n",
      "2. 0.5909999907016754 < NOX <= 0.6180000007152557 and 9.477545261383057 < LSTAT <= 12.607422828674316 => (0, 1) [0, 3, 0, 0, 0, 0]\n",
      "3. CRIM <= 1.4226450324058533 and NOX <= 0.5909999907016754 and PTRATIO > 20.600000381469727 and LSTAT > 17.515000343322754 => (0, 1) [0, 2, 0, 0, 0, 0]\n",
      "4. 0.5309999883174896 < NOX <= 0.5909999907016754 and DIS > 2.271081805229187 and 16.715493202209473 < LSTAT <= 17.515000343322754 => (0, 1) [0, 2, 0, 0, 0, 0]\n",
      "5. CRIM <= 5.023024320602417 and NOX <= 0.7439999878406525 and RM <= 6.61963152885437 and RAD > 6.0 and LSTAT <= 9.477545261383057 => (2, 1) [0, 0, 0, 0, 2, 0]\n",
      "6. CRIM > 0.9839633405208588 and NOX > 0.5909999907016754 and RM > 5.949499845504761 and 12.607422828674316 < LSTAT <= 14.309999942779541 => (0, 1) [0, 1, 0, 0, 0, 0]\n",
      "7. NOX <= 0.5909999907016754 and DIS > 2.271081805229187 and RAD > 4.5 and PTRATIO <= 16.5 and 9.477545261383057 < LSTAT <= 16.715493202209473 => (0, 1) [0, 1, 0, 0, 0, 0]\n",
      "8. CRIM > 0.01169000007212162 and RM > 6.61963152885437 and PTRATIO > 20.600000381469727 and LSTAT <= 9.477545261383057 => (2, 1) [0, 0, 0, 0, 1, 0]\n",
      "9. CRIM > 0.20502999424934387 and RM <= 6.61963152885437 and RAD <= 6.0 and LSTAT <= 6.255000114440918 => (1, 2) [0, 0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "constraints, rules, class_occurences, labels, instance_indices_per_rule =\\\n",
    "    extract_rules(model, feature_names, comparer.difference_classes, X, mclass_diff)\n",
    "print_rules(rules, class_occurences, comparer.class_names, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5df8a-5804-4760-a9e6-23ec9cbfba96",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349a084c-ec2a-435c-959a-70be419d0451",
   "metadata": {},
   "source": [
    "### Global Fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68dcb419-0a60-410a-89f9-59f7733266b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      (0, 0)       0.99      1.00      0.99        76\n",
      "      (0, 1)       1.00      1.00      1.00        13\n",
      "      (1, 1)       1.00      0.98      0.99        58\n",
      "      (1, 2)       1.00      1.00      1.00         1\n",
      "      (2, 1)       1.00      1.00      1.00         3\n",
      "      (2, 2)       1.00      1.00      1.00        95\n",
      "\n",
      "    accuracy                           1.00       246\n",
      "   macro avg       1.00      1.00      1.00       246\n",
      "weighted avg       1.00      1.00      1.00       246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(model, X, mclass_diff, comparer.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad1691-2972-4ee2-b7e9-b452068caa56",
   "metadata": {},
   "source": [
    "### Counterfactual Fidelity Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc1091b-886a-4399-b8a8-3137befc9e91",
   "metadata": {},
   "source": [
    "#### (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "664a14c3-ae4d-470a-a6b0-26a6625b099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_class_idx, focus_class = comparer.check_class('(0, 1)')\n",
    "ground_truth_instance_indices, ground_truth = ground_truth_per_class[focus_class]\n",
    "constraints_focus, rules_focus, class_occurences_focus, instance_indices_per_rule_focus =\\\n",
    "    zip(*[(constraint, rule, class_occurences, instance_indices)\n",
    "     for constraint, rule, class_occurences, label, instance_indices\n",
    "     in zip(constraints, rules, class_occurences, labels, instance_indices_per_rule)\n",
    "     if label == focus_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c506213a-40d5-4364-9e12-3fb04aab51e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "invalid value encountered in true_divide\n",
      "invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "errors, rmse, boundary_miss_rate, boundary_add_rate = \\\n",
    "    evaluate_counterfactual_fidelity(comparer, ground_truth_instance_indices, ground_truth, instance_indices_per_rule_focus, constraints_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a13c5209-34bb-4a23-9333-7d8ef5d38ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0.794867\n",
       "ZN              NaN\n",
       "INDUS           NaN\n",
       "NOX             NaN\n",
       "RM              NaN\n",
       "AGE             NaN\n",
       "DIS             NaN\n",
       "RAD        2.470000\n",
       "TAX             NaN\n",
       "PTRATIO    0.432782\n",
       "LSTAT      1.602040\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4c424f2-a27a-4438-95bb-3b97fcfea62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0.631579\n",
       "ZN         1.000000\n",
       "INDUS      1.000000\n",
       "NOX             NaN\n",
       "RM         1.000000\n",
       "AGE        1.000000\n",
       "DIS        1.000000\n",
       "RAD        0.937500\n",
       "TAX        1.000000\n",
       "PTRATIO    0.833333\n",
       "LSTAT      0.076923\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_miss_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa9b9f4e-50dd-4eb3-b81b-418e33b33a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0.0\n",
       "ZN         NaN\n",
       "INDUS      NaN\n",
       "NOX        1.0\n",
       "RM         1.0\n",
       "AGE        NaN\n",
       "DIS        1.0\n",
       "RAD        0.0\n",
       "TAX        NaN\n",
       "PTRATIO    0.0\n",
       "LSTAT      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_add_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0557ed89-4d99-4da6-b3df-c05649bb76f0",
   "metadata": {},
   "source": [
    "#### (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b030482-a64c-460c-adcd-7d83bfc40a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_class_idx, focus_class = comparer.check_class('(1, 2)')\n",
    "ground_truth_instance_indices, ground_truth = ground_truth_per_class[focus_class]\n",
    "constraints_focus, rules_focus, class_occurences_focus, instance_indices_per_rule_focus =\\\n",
    "    zip(*[(constraint, rule, class_occurences, instance_indices)\n",
    "     for constraint, rule, class_occurences, label, instance_indices\n",
    "     in zip(constraints, rules, class_occurences, labels, instance_indices_per_rule)\n",
    "     if label == focus_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a491b96f-19a9-47a6-b702-da1d3fbf0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, rmse, boundary_miss_rate, boundary_add_rate = \\\n",
    "    evaluate_counterfactual_fidelity(comparer, ground_truth_instance_indices, ground_truth, instance_indices_per_rule_focus, constraints_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3d8de01-f478-4d32-a071-1542800dc489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM            NaN\n",
       "ZN              NaN\n",
       "INDUS           NaN\n",
       "NOX             NaN\n",
       "RM         1.120368\n",
       "AGE             NaN\n",
       "DIS             NaN\n",
       "RAD        6.720000\n",
       "TAX             NaN\n",
       "PTRATIO         NaN\n",
       "LSTAT      0.015000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "439e71b4-65fa-4498-8564-6439a95f0bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       1.0\n",
       "ZN         1.0\n",
       "INDUS      1.0\n",
       "NOX        NaN\n",
       "RM         0.5\n",
       "AGE        1.0\n",
       "DIS        1.0\n",
       "RAD        0.5\n",
       "TAX        NaN\n",
       "PTRATIO    1.0\n",
       "LSTAT      0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_miss_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e05f2ad8-9c86-49eb-8378-2c72085eb772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       1.0\n",
       "ZN         NaN\n",
       "INDUS      NaN\n",
       "NOX        NaN\n",
       "RM         0.0\n",
       "AGE        NaN\n",
       "DIS        NaN\n",
       "RAD        0.0\n",
       "TAX        NaN\n",
       "PTRATIO    NaN\n",
       "LSTAT      0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_add_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0f99f-2391-4efb-b763-62ff027604ed",
   "metadata": {},
   "source": [
    "#### (2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09d39ce4-c30d-4cc6-b970-391caa01c87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_class_idx, focus_class = comparer.check_class('(2, 1)')\n",
    "ground_truth_instance_indices, ground_truth = ground_truth_per_class[focus_class]\n",
    "constraints_focus, rules_focus, class_occurences_focus, instance_indices_per_rule_focus =\\\n",
    "    zip(*[(constraint, rule, class_occurences, instance_indices)\n",
    "     for constraint, rule, class_occurences, label, instance_indices\n",
    "     in zip(constraints, rules, class_occurences, labels, instance_indices_per_rule)\n",
    "     if label == focus_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4a87a44-e6f9-44df-88cb-0c4017c055e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, rmse, boundary_miss_rate, boundary_add_rate = \\\n",
    "    evaluate_counterfactual_fidelity(comparer, ground_truth_instance_indices, ground_truth, instance_indices_per_rule_focus, constraints_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d1c6386-044b-4e37-9201-45bc348a3fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM        4.981600\n",
       "ZN               NaN\n",
       "INDUS            NaN\n",
       "NOX              NaN\n",
       "RM          1.361463\n",
       "AGE              NaN\n",
       "DIS              NaN\n",
       "RAD        11.720004\n",
       "TAX              NaN\n",
       "PTRATIO          NaN\n",
       "LSTAT       1.746977\n",
       "dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56d6dc9c-b71a-41e9-be4f-a02a3b9ae193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0.5\n",
       "ZN         1.0\n",
       "INDUS      1.0\n",
       "NOX        NaN\n",
       "RM         0.4\n",
       "AGE        1.0\n",
       "DIS        1.0\n",
       "RAD        0.5\n",
       "TAX        1.0\n",
       "PTRATIO    1.0\n",
       "LSTAT      0.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_miss_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "60f8d792-1af0-402f-985c-7baed19cbce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0.333333\n",
       "ZN              NaN\n",
       "INDUS           NaN\n",
       "NOX        1.000000\n",
       "RM         0.000000\n",
       "AGE             NaN\n",
       "DIS             NaN\n",
       "RAD        0.000000\n",
       "TAX             NaN\n",
       "PTRATIO    1.000000\n",
       "LSTAT      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boundary_add_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaeb4d6-83c1-43a5-9536-ddcda7c355d2",
   "metadata": {},
   "source": [
    "### Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424a5b9a-9d59-48d7-811a-82f7d088912e",
   "metadata": {},
   "source": [
    "#### (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "57def856-44dd-459e-bb02-37dcb957697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_class_idx, focus_class = comparer.check_class('(0, 1)')\n",
    "ground_truth_instance_indices, ground_truth = ground_truth_per_class[focus_class]\n",
    "constraints_focus, rules_focus, class_occurences_focus, instance_indices_per_rule_focus =\\\n",
    "    zip(*[(constraint, rule, class_occurences, instance_indices)\n",
    "     for constraint, rule, class_occurences, label, instance_indices\n",
    "     in zip(constraints, rules, class_occurences, labels, instance_indices_per_rule)\n",
    "     if label == focus_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e526677-4689-4b73-8484-69ef0b1d073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rules: 6\n",
      "Number of constraints: 29 (4.8 per rule)\n"
     ]
    }
   ],
   "source": [
    "print_complexity(constraints_focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187b1c1b-43af-4419-903c-2ca88a8d7059",
   "metadata": {},
   "source": [
    "#### (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "23faddff-db41-404d-890b-77794289ffc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_class_idx, focus_class = comparer.check_class('(1, 2)')\n",
    "ground_truth_instance_indices, ground_truth = ground_truth_per_class[focus_class]\n",
    "constraints_focus, rules_focus, class_occurences_focus, instance_indices_per_rule_focus =\\\n",
    "    zip(*[(constraint, rule, class_occurences, instance_indices)\n",
    "     for constraint, rule, class_occurences, label, instance_indices\n",
    "     in zip(constraints, rules, class_occurences, labels, instance_indices_per_rule)\n",
    "     if label == focus_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ce2aa40-caa6-41d9-b917-d6cb873861d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rules: 1\n",
      "Number of constraints: 4 (4.0 per rule)\n"
     ]
    }
   ],
   "source": [
    "print_complexity(constraints_focus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfec3b0d-9031-4f04-a691-8bc776c138d9",
   "metadata": {},
   "source": [
    "#### (2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "03a4c793-24f1-4e56-9447-13af3ba4657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_class_idx, focus_class = comparer.check_class('(2, 1)')\n",
    "ground_truth_instance_indices, ground_truth = ground_truth_per_class[focus_class]\n",
    "constraints_focus, rules_focus, class_occurences_focus, instance_indices_per_rule_focus =\\\n",
    "    zip(*[(constraint, rule, class_occurences, instance_indices)\n",
    "     for constraint, rule, class_occurences, label, instance_indices\n",
    "     in zip(constraints, rules, class_occurences, labels, instance_indices_per_rule)\n",
    "     if label == focus_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fa59f34-32be-4439-aed8-c4bedd26f9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rules: 2\n",
      "Number of constraints: 9 (4.5 per rule)\n"
     ]
    }
   ],
   "source": [
    "print_complexity(constraints_focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2287e75a-f90a-4657-8db1-70072c338fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
